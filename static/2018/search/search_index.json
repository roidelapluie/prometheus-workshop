{"config":{"lang":["en"],"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"Practical info Welcome to this Prometheus Workshop at OSMC 2018! Schedule 10:00 am: Start 11:30 am: Coffee Break 01:00 pm: Lunch at the Restaurant 03:30 pm: Coffee break 05:00 pm: End 07:00 pm: Dinner / get together at the Restaurant Online questionnaire During this afternoon, you will receive an online questionnaire. Please use it to provide feedback. Network setup Because clients are isolated by default, we will add a secondary interface on your laptop: $ sudo -i # service firewalld stop # ip ad ad 192.168.28.x/24 dev enp5s0 Where x will be given by the trainer.","title":"Practical info"},{"location":"#practical-info","text":"Welcome to this Prometheus Workshop at OSMC 2018!","title":"Practical info"},{"location":"#schedule","text":"10:00 am: Start 11:30 am: Coffee Break 01:00 pm: Lunch at the Restaurant 03:30 pm: Coffee break 05:00 pm: End 07:00 pm: Dinner / get together at the Restaurant","title":"Schedule"},{"location":"#online-questionnaire","text":"During this afternoon, you will receive an online questionnaire. Please use it to provide feedback.","title":"Online questionnaire"},{"location":"#network-setup","text":"Because clients are isolated by default, we will add a secondary interface on your laptop: $ sudo -i # service firewalld stop # ip ad ad 192.168.28.x/24 dev enp5s0 Where x will be given by the trainer.","title":"Network setup"},{"location":"alertmanager/","text":"Alerting In Prometheus Note Prometheus is using Go Templating System for alerting, in both Prometheus and Alertmanager Prometheus splits the alerting role in 3 components: prometheus server which will calculate the alerts alertmanager which will dispatch the alerts webhook receivers that will handle the alerts Exercise Create, in Prometheus, an alert when a target is down. Exercise Create, in Prometheus, an alert when a grafana server is down, with a label: priority=high. Exercise Create a recording rule to get the % of disk space used and alert on 50% of disk space used. What is the difference between recording and alerting? What is an annotation? What is a \"group\" of recording rules? How to see the rules and the alerts in the UI? What is a pending alert? Bonus: Alerts unit test (if there is enough time) Tip Prometheus generates an ALERTS metric with the active/pending alerts. Alertmanager Download and run Alertmanager Connect Prometheus and Alertmanager together Look for the alerts coming. What are the 4 roles of alertmanager? What are the different timers in alertmanager? Exercise Use https://webhook.site/ to get a webhook URL. Send alerts to that https://webhook.site/ URL. For the priority=high alerts, send an email instead of a webhook. Can you explain the HA model of prometheus? How can I send an alert to multiple targets? Exercise How can you check that two alertmanager config are in sync? Tip There is a alertmanager_config_hash metric Solution count(count_values(\"config\", alertmanager_config_hash)) != 1 Exercise Make a big cluster of alert managers Amtool Amtool is the CLI tool for alertmanager You can use it to e.g. create silences. Karma karma is a dashboard for alertmanager","title":"Alerting"},{"location":"alertmanager/#alerting","text":"","title":"Alerting"},{"location":"alertmanager/#in-prometheus","text":"Note Prometheus is using Go Templating System for alerting, in both Prometheus and Alertmanager Prometheus splits the alerting role in 3 components: prometheus server which will calculate the alerts alertmanager which will dispatch the alerts webhook receivers that will handle the alerts Exercise Create, in Prometheus, an alert when a target is down. Exercise Create, in Prometheus, an alert when a grafana server is down, with a label: priority=high. Exercise Create a recording rule to get the % of disk space used and alert on 50% of disk space used. What is the difference between recording and alerting? What is an annotation? What is a \"group\" of recording rules? How to see the rules and the alerts in the UI? What is a pending alert? Bonus: Alerts unit test (if there is enough time) Tip Prometheus generates an ALERTS metric with the active/pending alerts.","title":"In Prometheus"},{"location":"alertmanager/#alertmanager","text":"Download and run Alertmanager Connect Prometheus and Alertmanager together Look for the alerts coming. What are the 4 roles of alertmanager? What are the different timers in alertmanager? Exercise Use https://webhook.site/ to get a webhook URL. Send alerts to that https://webhook.site/ URL. For the priority=high alerts, send an email instead of a webhook. Can you explain the HA model of prometheus? How can I send an alert to multiple targets? Exercise How can you check that two alertmanager config are in sync? Tip There is a alertmanager_config_hash metric Solution count(count_values(\"config\", alertmanager_config_hash)) != 1 Exercise Make a big cluster of alert managers","title":"Alertmanager"},{"location":"alertmanager/#amtool","text":"Amtool is the CLI tool for alertmanager You can use it to e.g. create silences.","title":"Amtool"},{"location":"alertmanager/#karma","text":"karma is a dashboard for alertmanager","title":"Karma"},{"location":"bonus/","text":"Bonus If there is time left.. Pushgateway LTS Remote Read Remote Write Alert Rules unit testing Service Discovery TLS overview Console templates Graphite Exporter Collectd Grafonnet + Monitoring Mixins Q A","title":"Bonus"},{"location":"bonus/#bonus","text":"If there is time left.. Pushgateway LTS Remote Read Remote Write Alert Rules unit testing Service Discovery TLS overview Console templates Graphite Exporter Collectd Grafonnet + Monitoring Mixins Q A","title":"Bonus"},{"location":"custom/","text":"Integrating Prometheus metru Custom exercise with the crowd","title":"Custom apps"},{"location":"custom/#integrating-prometheus-metru","text":"Custom exercise with the crowd","title":"Integrating Prometheus metru"},{"location":"end/","text":"prometheus.yml # my global config global: scrape_interval: 15s # Set the scrape interval to every 15 seconds. Default is every 1 minute. evaluation_interval: 15s # Evaluate rules every 15 seconds. The default is every 1 minute. # scrape_timeout is set to the global default (10s). # Alertmanager configuration alerting: alertmanagers: - static_configs: - targets: - 192.168.26.1:9093 - 192.168.26.2:9093 # Load rules once and periodically evaluate them according to the global evaluation_interval . rule_files: - first_rules.yml # - second_rules.yml # A scrape configuration containing exactly one endpoint to scrape: # Here it s Prometheus itself. scrape_configs: # The job name is added as a label `job= job_name ` to any timeseries scraped from this config. - job_name: prometheus relabel_configs: - source_labels: [__address__] target_label: __address__ replacement: ${1}:9090 file_sd_configs: - files: - workshop.yml refresh_interval: 10s - job_name: node relabel_configs: - source_labels: [__address__] target_label: __address__ replacement: ${1}:9100 file_sd_configs: - files: - workshop.yml refresh_interval: 10s - job_name: grafana relabel_configs: - source_labels: [__address__] target_label: __address__ replacement: ${1}:3000 file_sd_configs: - files: - workshop.yml refresh_interval: 10s - job_name: federation metrics_path: /federate params: match[] : [up] relabel_configs: - source_labels: [__address__] target_label: __address__ replacement: ${1}:9090 metric_relabel_configs: - source_labels: [__name__] target_label: __name__ regex: up replacement: federate_up file_sd_configs: - files: - workshop.yml refresh_interval: 10s - job_name: jenkins relabel_configs: - source_labels: [__address__] target_label: __address__ replacement: ${1}:8081 file_sd_configs: - files: - workshop.yml refresh_interval: 10s - job_name: aletmanager relabel_configs: - source_labels: [__address__] target_label: __address__ replacement: ${1}:9093 file_sd_configs: - files: - workshop.yml refresh_interval: 10s - job_name: grok relabel_configs: - source_labels: [__address__] target_label: __address__ replacement: ${1}:9144 file_sd_configs: - files: - workshop.yml refresh_interval: 10s workshop.yml - targets: [ 192.168.26.1 ] labels: name: me - targets: - 192.168.26.3 - 192.168.26.4 - 192.168.26.5 - 192.168.26.6 - 192.168.26.7 labels: name: right - targets: - 192.168.26.8 - 192.168.26.9 - 192.168.26.10 - 192.168.26.11 - 192.168.26.12 - 192.168.26.13 - 192.168.26.14 - 192.168.26.15 labels: name: left first_rules.yml groups: - name: example rules: - alert: a target is down for: 5m expr: up == 0 labels: priority: high annotations: text: {{$labels.job}} is down! grok_exporter.yml global: config_version: 2 input: type: file path: ../jenkins.log readall: true grok: patterns_dir: ./patterns metrics: - type: counter name: job_build_total help: Counter for the job runs. match: INFO: %{WORD:jobname} #%{NUMBER:jobid} main build action completed: %{WORD:status} labels: jobname: {{.jobname}} status: {{.status}} - type: gauge name: job_last_build_number help: Number of the last build match: INFO: %{WORD:jobname} #%{NUMBER:jobid} main build action completed: %{WORD:status} labels: jobname: {{.jobname}} value: {{.jobid}} server: port: 9144 alertmanager.yml global: resolve_timeout: 5m route: group_by: [ alertname ] group_wait: 10s group_interval: 10s repeat_interval: 1h receiver: web.hook routes: - match: priority: high continue: true receiver: sms.hook receivers: - name: sms.hook webhook_configs: - url: https://webhook.site/5c702a0d-2c02-4f70-a8ee-9ac45d2ce2b9 - name: web.hook webhook_configs: - url: https://webhook.site/5c702a0d-2c02-4f70-a8ee-9ac45d2ce2b9 inhibit_rules: - source_match: severity: critical target_match: severity: warning equal: [ alertname , dev , instance ]","title":"Config files"},{"location":"end/#prometheusyml","text":"# my global config global: scrape_interval: 15s # Set the scrape interval to every 15 seconds. Default is every 1 minute. evaluation_interval: 15s # Evaluate rules every 15 seconds. The default is every 1 minute. # scrape_timeout is set to the global default (10s). # Alertmanager configuration alerting: alertmanagers: - static_configs: - targets: - 192.168.26.1:9093 - 192.168.26.2:9093 # Load rules once and periodically evaluate them according to the global evaluation_interval . rule_files: - first_rules.yml # - second_rules.yml # A scrape configuration containing exactly one endpoint to scrape: # Here it s Prometheus itself. scrape_configs: # The job name is added as a label `job= job_name ` to any timeseries scraped from this config. - job_name: prometheus relabel_configs: - source_labels: [__address__] target_label: __address__ replacement: ${1}:9090 file_sd_configs: - files: - workshop.yml refresh_interval: 10s - job_name: node relabel_configs: - source_labels: [__address__] target_label: __address__ replacement: ${1}:9100 file_sd_configs: - files: - workshop.yml refresh_interval: 10s - job_name: grafana relabel_configs: - source_labels: [__address__] target_label: __address__ replacement: ${1}:3000 file_sd_configs: - files: - workshop.yml refresh_interval: 10s - job_name: federation metrics_path: /federate params: match[] : [up] relabel_configs: - source_labels: [__address__] target_label: __address__ replacement: ${1}:9090 metric_relabel_configs: - source_labels: [__name__] target_label: __name__ regex: up replacement: federate_up file_sd_configs: - files: - workshop.yml refresh_interval: 10s - job_name: jenkins relabel_configs: - source_labels: [__address__] target_label: __address__ replacement: ${1}:8081 file_sd_configs: - files: - workshop.yml refresh_interval: 10s - job_name: aletmanager relabel_configs: - source_labels: [__address__] target_label: __address__ replacement: ${1}:9093 file_sd_configs: - files: - workshop.yml refresh_interval: 10s - job_name: grok relabel_configs: - source_labels: [__address__] target_label: __address__ replacement: ${1}:9144 file_sd_configs: - files: - workshop.yml refresh_interval: 10s","title":"prometheus.yml"},{"location":"end/#workshopyml","text":"- targets: [ 192.168.26.1 ] labels: name: me - targets: - 192.168.26.3 - 192.168.26.4 - 192.168.26.5 - 192.168.26.6 - 192.168.26.7 labels: name: right - targets: - 192.168.26.8 - 192.168.26.9 - 192.168.26.10 - 192.168.26.11 - 192.168.26.12 - 192.168.26.13 - 192.168.26.14 - 192.168.26.15 labels: name: left","title":"workshop.yml"},{"location":"end/#first_rulesyml","text":"groups: - name: example rules: - alert: a target is down for: 5m expr: up == 0 labels: priority: high annotations: text: {{$labels.job}} is down!","title":"first_rules.yml"},{"location":"end/#grok_exporteryml","text":"global: config_version: 2 input: type: file path: ../jenkins.log readall: true grok: patterns_dir: ./patterns metrics: - type: counter name: job_build_total help: Counter for the job runs. match: INFO: %{WORD:jobname} #%{NUMBER:jobid} main build action completed: %{WORD:status} labels: jobname: {{.jobname}} status: {{.status}} - type: gauge name: job_last_build_number help: Number of the last build match: INFO: %{WORD:jobname} #%{NUMBER:jobid} main build action completed: %{WORD:status} labels: jobname: {{.jobname}} value: {{.jobid}} server: port: 9144","title":"grok_exporter.yml"},{"location":"end/#alertmanageryml","text":"global: resolve_timeout: 5m route: group_by: [ alertname ] group_wait: 10s group_interval: 10s repeat_interval: 1h receiver: web.hook routes: - match: priority: high continue: true receiver: sms.hook receivers: - name: sms.hook webhook_configs: - url: https://webhook.site/5c702a0d-2c02-4f70-a8ee-9ac45d2ce2b9 - name: web.hook webhook_configs: - url: https://webhook.site/5c702a0d-2c02-4f70-a8ee-9ac45d2ce2b9 inhibit_rules: - source_match: severity: critical target_match: severity: warning equal: [ alertname , dev , instance ]","title":"alertmanager.yml"},{"location":"exporters/","text":"Exporters node_exporter The node exporter enables basic monitoring of linux machines (and other unix like systems.) Download and run the node_exporter Enable the systemd collector (might require to run as root) Add your node_exporter and your neighbors to prometheus textfile collector Exercise Move the metrics created before (company name, random number..) on port 5678 to be collected by the node exporter. Do you see use cases for this feature? Dashboards Exercise Create two dashboards: a dashboard that will show the network bandwidth of a server by interface, and a dashboard that will show the disk space available per disk. Tip You can use {job=\"node_exporter\"} in prometheus to see the metrics, or you can directly open the /metrics of the node_exporter in your browser. JMX exporter Download Jenkins Download the JMX exporter Run Jenkins with the JMX exporter and add it to Prometheus Solution java -javaagent:./jmx_prometheus_javaagent-0.3.1.jar=8081:config.yml -jar jenkins.war config.yml --- startDelaySeconds: 0 exercise Create a dashboard with: JVM version Uptime Threads Heap Size Memory Pool size Grok exporter Download grok exporter Create a simple job in Jenkins Re run Jenkins to output to a file (add jenkins.log ) exercise Create a job with name \"test\" and command \"sleep 10\" Run the job and look for \"INFO: test #2 main build action completed: SUCCESS\" in the logs Create a counter and a gauge for those: job_last_build_number and job_build_total . The name of the job should be a label, and for the job_build_total the status should too be a label. Solution global: config_version: 2 input: type: file path: ../jenkins.log readall: true grok: patterns_dir: ./patterns metrics: - type: counter name: job_build_total help: Counter for the job runs. match: INFO: %{WORD:jobname} #%{NUMBER:jobid} main build action completed: %{WORD:status} labels: jobname: {{.jobname}} status: {{.status}} - type: gauge name: job_last_build_number help: Number of the last build match: INFO: %{WORD:jobname} #%{NUMBER:jobid} main build action completed: %{WORD:status} labels: jobname: {{.jobname}} value: {{.jobid}} server: port: 9144 Blackbox exporter Exercise Monitor the OSMC website (DNS + HTTP) using the blackbox exporter Check with prometheus blackbox exporter when the SSL certificate will expire in days Create a dashboard with the detailed time it takes to get the OSMC website.","title":"Exporters"},{"location":"exporters/#exporters","text":"","title":"Exporters"},{"location":"exporters/#node_exporter","text":"The node exporter enables basic monitoring of linux machines (and other unix like systems.) Download and run the node_exporter Enable the systemd collector (might require to run as root) Add your node_exporter and your neighbors to prometheus","title":"node_exporter"},{"location":"exporters/#textfile-collector","text":"Exercise Move the metrics created before (company name, random number..) on port 5678 to be collected by the node exporter. Do you see use cases for this feature?","title":"textfile collector"},{"location":"exporters/#dashboards","text":"Exercise Create two dashboards: a dashboard that will show the network bandwidth of a server by interface, and a dashboard that will show the disk space available per disk. Tip You can use {job=\"node_exporter\"} in prometheus to see the metrics, or you can directly open the /metrics of the node_exporter in your browser.","title":"Dashboards"},{"location":"exporters/#jmx-exporter","text":"Download Jenkins Download the JMX exporter Run Jenkins with the JMX exporter and add it to Prometheus Solution java -javaagent:./jmx_prometheus_javaagent-0.3.1.jar=8081:config.yml -jar jenkins.war config.yml --- startDelaySeconds: 0 exercise Create a dashboard with: JVM version Uptime Threads Heap Size Memory Pool size","title":"JMX exporter"},{"location":"exporters/#grok-exporter","text":"Download grok exporter Create a simple job in Jenkins Re run Jenkins to output to a file (add jenkins.log ) exercise Create a job with name \"test\" and command \"sleep 10\" Run the job and look for \"INFO: test #2 main build action completed: SUCCESS\" in the logs Create a counter and a gauge for those: job_last_build_number and job_build_total . The name of the job should be a label, and for the job_build_total the status should too be a label. Solution global: config_version: 2 input: type: file path: ../jenkins.log readall: true grok: patterns_dir: ./patterns metrics: - type: counter name: job_build_total help: Counter for the job runs. match: INFO: %{WORD:jobname} #%{NUMBER:jobid} main build action completed: %{WORD:status} labels: jobname: {{.jobname}} status: {{.status}} - type: gauge name: job_last_build_number help: Number of the last build match: INFO: %{WORD:jobname} #%{NUMBER:jobid} main build action completed: %{WORD:status} labels: jobname: {{.jobname}} value: {{.jobid}} server: port: 9144","title":"Grok exporter"},{"location":"exporters/#blackbox-exporter","text":"Exercise Monitor the OSMC website (DNS + HTTP) using the blackbox exporter Check with prometheus blackbox exporter when the SSL certificate will expire in days Create a dashboard with the detailed time it takes to get the OSMC website.","title":"Blackbox exporter"},{"location":"grafana/","text":"Grafana Download and run grafana Go to the Grafana website and download the latest stable release For this exercise we will use the Standalone Linux Binaries(64 Bit) $ wget https://s3-us-west-2.amazonaws.com/grafana-releases/release/grafana-5.3.2.linux-amd64.tar.gz $ tar -zxvf grafana-5.3.2.linux-amd64.tar.gz $ cd grafana-5.3.2 $ ./bin/grafana-server Open Grafana in your browser Setup prometheus Add your prometheus server as a datasource + import the prometheus dashboards Monitor grafana in prometheus (add it as a target) Look at the grafana dashboards Create a new dashboard Create a new dashboard which enables you to pick someone's prometheus and gather info: samples scrapes, scrape duration, ... using variables . Your dashboard should contain at least a singlestat panel, a variable and a graph panel. Info Grafana also support tables and heapmaps for Prometheus","title":"Grafana"},{"location":"grafana/#grafana","text":"","title":"Grafana"},{"location":"grafana/#download-and-run-grafana","text":"Go to the Grafana website and download the latest stable release For this exercise we will use the Standalone Linux Binaries(64 Bit) $ wget https://s3-us-west-2.amazonaws.com/grafana-releases/release/grafana-5.3.2.linux-amd64.tar.gz $ tar -zxvf grafana-5.3.2.linux-amd64.tar.gz $ cd grafana-5.3.2 $ ./bin/grafana-server Open Grafana in your browser","title":"Download and run grafana"},{"location":"grafana/#setup-prometheus","text":"Add your prometheus server as a datasource + import the prometheus dashboards Monitor grafana in prometheus (add it as a target) Look at the grafana dashboards","title":"Setup prometheus"},{"location":"grafana/#create-a-new-dashboard","text":"Create a new dashboard which enables you to pick someone's prometheus and gather info: samples scrapes, scrape duration, ... using variables . Your dashboard should contain at least a singlestat panel, a variable and a graph panel. Info Grafana also support tables and heapmaps for Prometheus","title":"Create a new dashboard"},{"location":"metrics/","text":"Metrics Monitoring Metrics monitoring is different because it does not assume that a situation can be explained in fixed states. Instead, it brings you inside your system and provides dizens of metrics that you can then analyze and understand. Even if you do not need all the metrics, it is better to collect them to look further what they look like. What is a metrics Name Timestamp Labels Value Type What are the 4 types of metrics prometheus knows? Gauge Counters Histograms Summaries The number of http requests is expressed in ... The duration in ... The number of active sessions is a ... What are the labels added by prometheus ? What are the labels prometheus knows but does not add? Labels matching For prometheus to do calculations and comparisons of metrics, labels must match one each side (except name) Functions Some important functions: Math: = - / * rate sum deriv delta increase count In the list above, which ones should be used with counters, and which ones with gauges? What is the difference between irate and rate? idelta and delta? Aggregation How can I get the sum of scraped metrics by job (2 ways)? -- exclusion and inclusion. How can I get the % of /federate over the other prometheus_http_request_duration_seconds_count ? Solution rate(prometheus_http_request_duration_seconds_count{handler= /federate }[5m]) / ignoring(handler) group_right sum without (handler) (rate(prometheus_http_request_duration_seconds_count[5m])) Over Time What is the difference between max and max_over_time? Max, Min, Bottomk, Topk What is the difference between max and topk? Time functions day() day_of_week() How to use the optional argument of day_of_week? What is the timestamp() function? How can it be useful? Tip You can use Grafana Explore feature to get help and autocomplete on Prometheus (currently still a \"beta\" feature). And/Or Can you think of any usecases for and/or/unless?","title":"Metrics"},{"location":"metrics/#metrics-monitoring","text":"Metrics monitoring is different because it does not assume that a situation can be explained in fixed states. Instead, it brings you inside your system and provides dizens of metrics that you can then analyze and understand. Even if you do not need all the metrics, it is better to collect them to look further what they look like.","title":"Metrics Monitoring"},{"location":"metrics/#what-is-a-metrics","text":"Name Timestamp Labels Value Type What are the 4 types of metrics prometheus knows? Gauge Counters Histograms Summaries The number of http requests is expressed in ... The duration in ... The number of active sessions is a ... What are the labels added by prometheus ? What are the labels prometheus knows but does not add?","title":"What is a metrics"},{"location":"metrics/#labels-matching","text":"For prometheus to do calculations and comparisons of metrics, labels must match one each side (except name)","title":"Labels matching"},{"location":"metrics/#functions","text":"Some important functions: Math: = - / * rate sum deriv delta increase count In the list above, which ones should be used with counters, and which ones with gauges? What is the difference between irate and rate? idelta and delta?","title":"Functions"},{"location":"metrics/#aggregation","text":"How can I get the sum of scraped metrics by job (2 ways)? -- exclusion and inclusion. How can I get the % of /federate over the other prometheus_http_request_duration_seconds_count ? Solution rate(prometheus_http_request_duration_seconds_count{handler= /federate }[5m]) / ignoring(handler) group_right sum without (handler) (rate(prometheus_http_request_duration_seconds_count[5m]))","title":"Aggregation"},{"location":"metrics/#over-time","text":"What is the difference between max and max_over_time?","title":"Over Time"},{"location":"metrics/#max-min-bottomk-topk","text":"What is the difference between max and topk?","title":"Max, Min, Bottomk, Topk"},{"location":"metrics/#time-functions","text":"day() day_of_week() How to use the optional argument of day_of_week? What is the timestamp() function? How can it be useful? Tip You can use Grafana Explore feature to get help and autocomplete on Prometheus (currently still a \"beta\" feature).","title":"Time functions"},{"location":"metrics/#andor","text":"Can you think of any usecases for and/or/unless?","title":"And/Or"},{"location":"prometheus/","text":"Prometheus Prometheus is an open source monitoring system designed around metrics. It is a large ecosystem, with plenty of different components. Note The prometheus documentation provides an overview of those components The Prometheus server Download the prometheus server 2.5.0-rc.2. Extract it $ tar xvf Downloads/prometheus-2.5.0-rc.2.linux-amd64.tar.gz List the files $ ls prometheus-2.5.0-rc.2.linux-amd64 Launch prometheus $ cd prometheus-2.5.0-rc.2.linux-amd64 $ ./prometheus Open your browser at http://127.0.0.1:9090 Look at the TSDB data Note prometheus/tsdb is the database backend of prometheus. It is maintained by the prometheus team. The web ui There is a lot of information that can be found in the prometheus server web ui. Try to find: The version of prometheus The duration of data retention The \"targets\" that are scraped by default The \"scrape\" interval promtool promtool is a command line tool provided with Prometheus. With promtool you can: Query Prometheus ./promtool query instant http://127.0.0.1:9090 up Info the up metric is added by prometheus on each scrape. It is 1 if the scrape has succeeded, 0 otherwise. Validate Prometheus configuration ./promtool check config prometheus.yml Adding targets Note At this point, make sure you understand the basis of YAML exercise Open prometheus.yml Add each one's prometheus server as targets to your prometheus server. Look the status (using up or the target page) What is a job? What is an instance? Tip You do not need to reload prometheus: you can just send a SIGHUP signal to reload the configuration: killall -HUP prometheus Admin commands Enable admin commmands $ ./prometheus --web.enable-admin-api Take a snapshot $ curl -XPOST http://localhost:9090/api/v1/admin/tsdb/snapshot Look in the data directory Delete a timeserie $ curl -X POST -g http://localhost:9090/api/v1/admin/tsdb/delete_series?match[]=process_start_time_seconds{job= prometheus } Federation Now, let's move to file_sd. Create a file: - targets: - 127.0.0.1 labels: name: Julien - targets: - 127.0.0.2 labels: name: John With your IP + your neighbors. Name it users.yml . Adapt Prometheus configuration: - job_name: prometheus # metrics_path defaults to /metrics # scheme defaults to http . file_sd_configs: - files: - users.yml relabel_configs: - source_labels: [__address__] target_label: __address__ replacement: ${1}:9090 Duplicate the job, but with the following instructions: The new job should be called \"federation\" The new job should query http://127.0.0.1:9090/federate?match[]=up The \"up\" metric fetched should be renamed to external_up Tip The name of a metric is a label too! It is the __name__ label. Solution - job_name: federation metrics_path: /federate params: match[] : - up file_sd_configs: - files: - users.yml relabel_configs: - source_labels: [__address__] target_label: __address__ replacement: ${1}:9090 metric_relabel_configs: - source_labels: [__name__] target_label: __name__ regex: up replacement: federate_up Last exercise Prometheus fetches Metrics as HTML. Metrics have a name and labels. As an exercise, let's build on top of our previous example: In a new directory, create a file called \"metrics\" Add some metrics: company{name= inuits } 1 favorite_color{name= red } 1 random_number 10 workshop_step 1 then, run python -m SimpleHTTPServer 5678 and add it to prometheus (and your neighbors too).","title":"Prometheus"},{"location":"prometheus/#prometheus","text":"Prometheus is an open source monitoring system designed around metrics. It is a large ecosystem, with plenty of different components. Note The prometheus documentation provides an overview of those components","title":"Prometheus"},{"location":"prometheus/#the-prometheus-server","text":"Download the prometheus server 2.5.0-rc.2. Extract it $ tar xvf Downloads/prometheus-2.5.0-rc.2.linux-amd64.tar.gz List the files $ ls prometheus-2.5.0-rc.2.linux-amd64 Launch prometheus $ cd prometheus-2.5.0-rc.2.linux-amd64 $ ./prometheus Open your browser at http://127.0.0.1:9090 Look at the TSDB data Note prometheus/tsdb is the database backend of prometheus. It is maintained by the prometheus team.","title":"The Prometheus server"},{"location":"prometheus/#the-web-ui","text":"There is a lot of information that can be found in the prometheus server web ui. Try to find: The version of prometheus The duration of data retention The \"targets\" that are scraped by default The \"scrape\" interval","title":"The web ui"},{"location":"prometheus/#promtool","text":"promtool is a command line tool provided with Prometheus. With promtool you can: Query Prometheus ./promtool query instant http://127.0.0.1:9090 up Info the up metric is added by prometheus on each scrape. It is 1 if the scrape has succeeded, 0 otherwise. Validate Prometheus configuration ./promtool check config prometheus.yml","title":"promtool"},{"location":"prometheus/#adding-targets","text":"Note At this point, make sure you understand the basis of YAML exercise Open prometheus.yml Add each one's prometheus server as targets to your prometheus server. Look the status (using up or the target page) What is a job? What is an instance? Tip You do not need to reload prometheus: you can just send a SIGHUP signal to reload the configuration: killall -HUP prometheus","title":"Adding targets"},{"location":"prometheus/#admin-commands","text":"Enable admin commmands $ ./prometheus --web.enable-admin-api Take a snapshot $ curl -XPOST http://localhost:9090/api/v1/admin/tsdb/snapshot Look in the data directory Delete a timeserie $ curl -X POST -g http://localhost:9090/api/v1/admin/tsdb/delete_series?match[]=process_start_time_seconds{job= prometheus }","title":"Admin commands"},{"location":"prometheus/#federation","text":"Now, let's move to file_sd. Create a file: - targets: - 127.0.0.1 labels: name: Julien - targets: - 127.0.0.2 labels: name: John With your IP + your neighbors. Name it users.yml . Adapt Prometheus configuration: - job_name: prometheus # metrics_path defaults to /metrics # scheme defaults to http . file_sd_configs: - files: - users.yml relabel_configs: - source_labels: [__address__] target_label: __address__ replacement: ${1}:9090 Duplicate the job, but with the following instructions: The new job should be called \"federation\" The new job should query http://127.0.0.1:9090/federate?match[]=up The \"up\" metric fetched should be renamed to external_up Tip The name of a metric is a label too! It is the __name__ label. Solution - job_name: federation metrics_path: /federate params: match[] : - up file_sd_configs: - files: - users.yml relabel_configs: - source_labels: [__address__] target_label: __address__ replacement: ${1}:9090 metric_relabel_configs: - source_labels: [__name__] target_label: __name__ regex: up replacement: federate_up","title":"Federation"},{"location":"prometheus/#last-exercise","text":"Prometheus fetches Metrics as HTML. Metrics have a name and labels. As an exercise, let's build on top of our previous example: In a new directory, create a file called \"metrics\" Add some metrics: company{name= inuits } 1 favorite_color{name= red } 1 random_number 10 workshop_step 1 then, run python -m SimpleHTTPServer 5678 and add it to prometheus (and your neighbors too).","title":"Last exercise"}]}